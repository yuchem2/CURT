{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNvddFWeKLei4zpfkjxfXBa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## start"],"metadata":{"id":"zGMUrz0WNfMx"}},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OWO1NopHD_wD","executionInfo":{"status":"ok","timestamp":1666505364315,"user_tz":-540,"elapsed":2924,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}},"outputId":"5ea00dc5-b37c-4680-c6b8-11b4befc9ac3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import cv2\n","import random\n","import numpy as np\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pandas as pd\n","import torchvision\n","import torchvision.transforms as tt\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import random_split, DataLoader, Dataset\n","from google.colab import drive\n","torch.manual_seed(777)\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","   device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","print(device)\n","\n","def to_device(data, device):\n","    if isinstance(data, (list, tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","\n","    def __iter__(self):\n","        for b in self.dl:\n","            yield to_device(b, self.device)\n","    \n","    def __len__(self):\n","        return len(self.dl)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Koi6NF3QEDJl","executionInfo":{"status":"ok","timestamp":1666501398893,"user_tz":-540,"elapsed":2,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}},"outputId":"403c6456-f321-43da-a9ce-761dd0cd9b5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["## file directory: ICPS_Challenge_Data/label(1-40)/image_name.jpg\n","class MyDataset(Dataset):\n","    def __init__(self, path):\n","        self.path = path\n","        classes = os.listdir(self.path)\n","        print(classes)\n","        cmap = {v:i for i, v in enumerate(classes)}\n","        self.x = []\n","        self.y = []\n","        for label in tqdm(classes):\n","            #for data in os.listdir(self.path+'/'+label):\n","            listdir = os.listdir(self.path+'/'+label)\n","            datalist = random.sample(listdir, 50)\n","            for data in datalist:\n","                x = cv2.imread(self.path+'/'+label+'/'+data).astype(np.uint8)\n","                x = cv2.resize(x,(64, 64)).transpose((2, 0, 1))\n","                self.x.append(x)\n","                del x \n","                self.y.append(cmap[label])\n","        del cmap, classes\n","\n","    def __len__(self):\n","        return len(self.x)\n","        \n","    def __getitem__(self, idx):\n","        x = torch.from_numpy(self.x[idx])/255\n","        y = self.y[idx]\n","        return x, y"],"metadata":{"id":"aYruiWtEEDvF","executionInfo":{"status":"ok","timestamp":1666504000974,"user_tz":-540,"elapsed":475,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["dataPath = '/content/drive/Shareddrives/ICPS_Challenge_Data'\n","dataList = os.listdir(dataPath)\n","print(dataList)\n","\n","testData = MyDataset(dataPath)\n","print(len(testData))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AyTpMcufEFVF","outputId":"33a144c0-564e-4c20-c417-ddee5fd582b0","executionInfo":{"status":"ok","timestamp":1666503431316,"user_tz":-540,"elapsed":1033384,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}}},"execution_count":4,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40']\n","['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40']\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 40/40 [33:40<00:00, 50.51s/it]"]},{"output_type":"stream","name":"stdout","text":["2000 2000\n","2000\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["test_dl = DataLoader(testData)"],"metadata":{"id":"s-OK-UG5OhSi","executionInfo":{"status":"ok","timestamp":1666503905551,"user_tz":-540,"elapsed":1,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## model class"],"metadata":{"id":"fpNdKG0CNRil"}},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","def conv_block(in_channel, out_channel, pool=False):\n","    layers = [nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, stride=1), nn.ReLU(True)]\n","    if pool:\n","        layers.append(nn.MaxPool2d(2,2))\n","    return nn.Sequential(*layers)\n","\n","class ImageClassfication(nn.Module):\n","    def train_step(self, batch):\n","        images, classes = batch\n","        out = self(images)          #Generate prediction\n","        loss = F.cross_entropy(out, classes)   #Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        images, classes = batch\n","        out = self(images)                  \n","        loss = F.cross_entropy(out, classes)\n","        acc = accuracy(out, classes)            #Calculate Accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n","\n","class VGG19(ImageClassfication):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            conv_block(3, 64),\n","            conv_block(64, 64, True),   #64x64x64\n","\n","            conv_block(64, 128),\n","            conv_block(128, 128, True), #128x32x32\n","\n","            conv_block(128, 256),\n","            conv_block(256, 256),\n","            conv_block(256, 256),\n","            conv_block(256, 256, True), #256x16x16\n","\n","            conv_block(256, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512, True), #512x8x8\n","\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512, True), #512x4x4\n","\n","            #classifier\n","            nn.Sequential(\n","                nn.Flatten(), \n","                nn.Linear(512 * 2 * 2, 1024),\n","                nn.ReLU(True),\n","                nn.Dropout(),\n","                nn.Linear(1024, 1024),\n","                nn.ReLU(True),\n","                nn.Dropout(),\n","                nn.Linear(1024, num_classes)\n","                )\n","        )\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, xb):\n","         return self.network(xb)"],"metadata":{"id":"qEyMvbGZNS_1","executionInfo":{"status":"ok","timestamp":1666503908397,"user_tz":-540,"elapsed":1,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","def conv_block(in_channel, out_channel, pool=False):\n","    layers = [nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, stride=1), nn.ReLU(True)]\n","    if pool:\n","        layers.append(nn.MaxPool2d(2,2))\n","    return nn.Sequential(*layers)\n","\n","class ImageClassfication(nn.Module):\n","    def train_step(self, batch):\n","        images, classes = batch\n","        out = self(images)          #Generate prediction\n","        loss = F.cross_entropy(out, classes)   #Calculate loss\n","        return loss\n","\n","    def validation_step(self, batch):\n","        images, classes = batch\n","        out = self(images)                  \n","        loss = F.cross_entropy(out, classes)\n","        acc = accuracy(out, classes)            #Calculate Accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","\n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n","\n","class VGG19(ImageClassfication):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.network = nn.Sequential(\n","            conv_block(3, 64),\n","            conv_block(64, 64, True),   #64x64x64\n","\n","            conv_block(64, 128),\n","            conv_block(128, 128, True), #128x32x32\n","\n","            conv_block(128, 256),\n","            conv_block(256, 256),\n","            conv_block(256, 256),\n","            conv_block(256, 256, True), #256x16x16\n","\n","            conv_block(256, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512, True), #512x8x8\n","\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512),\n","            conv_block(512, 512, True), #512x4x4\n","\n","            #classifier\n","            nn.Sequential(\n","                nn.Flatten(), \n","                nn.Linear(512 * 2 * 2, 1024),\n","                nn.ReLU(True),\n","                nn.Dropout(),\n","                nn.Linear(1024, 1024),\n","                nn.ReLU(True),\n","                nn.Dropout(),\n","                nn.Linear(1024, num_classes)\n","                )\n","        )\n","        self._initialize_weights()\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","                if m.bias is not None:\n","                    nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight, 0, 0.01)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, xb):\n","         return self.network(xb)"],"metadata":{"id":"5mYWWV2sNXUl","executionInfo":{"status":"ok","timestamp":1666503910487,"user_tz":-540,"elapsed":1,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## Test"],"metadata":{"id":"2H3y77EBNb9E"}},{"cell_type":"code","source":["!ls\n","os.chdir('/content/drive/MyDrive')"],"metadata":{"id":"huTEpy63NasW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666503922175,"user_tz":-540,"elapsed":642,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}},"outputId":"0025f52d-d25c-4313-f667-72250cc1ba59"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["'Colab Notebooks'\t  icps_challenge.onnx   kinect_vgg19.pth\n"," curt_challenge_1.ipynb   icpsChallenge.onnx\n","'ICPS (1).ipynb'\t  kinect.pth\n"]}]},{"cell_type":"code","source":["test_model = torch.load('./kinect_vgg19.pth')\n","test_model.to(device)\n","test_dl = DeviceDataLoader(test_dl, device)\n","\n","yes = 0\n","no = 0\n","for images, labels in tqdm(test_dl):\n","    out = test_model(images)\n","    _, pred = torch.max(out, dim=1)\n","    for i in range(len(pred)):\n","        if  pred[i] == labels[i]:\n","            yes = yes + 1\n","        else:\n","            no = no +1\n","\n","total = yes + no\n","correct_percent = yes/total * 100\n","print(\"\\ntesting result:\", correct_percent, \"%\")"],"metadata":{"id":"1m67LpNDNbjE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666504014937,"user_tz":-540,"elapsed":9108,"user":{"displayName":"‍윤재현[ 학부재학 / 컴퓨터융합소프트웨어학과 ]","userId":"09250309820843633708"}},"outputId":"8c23a413-4fcd-4a9b-ac44-14129cea6a67"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2000 2000\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 13/2000 [00:00<00:15, 125.80it/s]"]},{"output_type":"stream","name":"stdout","text":["2000 2000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [00:08<00:00, 235.21it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","testing result: 97.95 %\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}